{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<small><img src=https://raw.githubusercontent.com/ia4legos/MachineLearning/main/images/IASAC-UMH.png width=\"450\" height=\"200\"></small>"],"metadata":{"id":"B_nLIZQZM4CV"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Introducción al álgebra lineal</font>\n","\n","**Autoría**: \n","\n","*   Fernando Borrás (f.borras@umh.es)\n","*   Federico Botella (federico@umh.es)\n","*   Inés Hernández (ineshp@umh.es)\n","*   Mª Asunción Martínez Mayoral (asun.mayoral@umh.es)\n","*   Josep Moltó (j.molto@umh.es)\n","*   Javier Morales (j.morales@umh.es) \n","\n","Departamento de Estadística, Matemáticas e Informática. \n","\n","Universidad Miguel Hernández de Elche. \n","\n","\n","**Financiación**: El material que aparece a continuación se ha desarrollado dentro del marco del proyecto UNIDIGITAL- IASAC.\n","\n","**Fecha última edición**: 31/05/2022\n","\n","**Licencia**: <small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /></small>\n","\n","No olvides hacer una copia si deseas utilizarlo. Al usar estos contenidos, acepta nuestros términos de uso y nuestra política de privacidad. \n"],"metadata":{"id":"-7whhErFzY9J"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Introducción</font>\n","\n","\n","**Descripción:** En este cuaderno se hace una pequeña introducción al álgebra lineal necesaria en los diferentes algoritmos de aprendizaje automático que estudiaremos más adelante.\n","\n","**Nivel de Formación:** B.\n","\n","**Recomendaciones antes de usarlo:** Conocimientos básicos del lenguaje Python, álgebra lineal y del módulo Numpy.\n","\n","**Objetivos de aprendizaje:**\n","\n","* Repasar los conceptos de álgebra matricial necesarios para el desarrollo de algoritmos de aprendizaje automático.\n","\n"],"metadata":{"id":"Wt99G2Jk5jX4"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Contenidos</font>\n","\n","1. Álgebra lineal.\n","2. Escalares, Vectores, Matrices y Tensores.\n","3. Vectores y matrices especiales.\n","4. Operaciones con vectores.\n","5. Operacones con matrices.\n","6. Características de una matriz."],"metadata":{"id":"wdhNCOuXPO0X"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Álgebra lineal</font>"],"metadata":{"id":"1d_3-DKt7Ige"}},{"cell_type":"markdown","source":["El álgebra lineal es al aprendizaje automático como la harina a la panadería: todo modelo de aprendizaje automático se basa en el álgebra lineal, como todo pastel se basa en la harina. No es el único ingrediente, por supuesto. Los modelos de aprendizaje automático necesitan el cálculo vectorial, la probabilidad y la optimización, como los pasteles necesitan azúcar, huevos y mantequilla. El aprendizaje automático aplicado, al igual que la pastelería, consiste esencialmente en combinar estos ingredientes matemáticos de forma inteligente para crear modelos útiles.\n","\n","Este documento contiene los fundamentos de álgebra lineal a nivel introductorio para el aprendizaje automático aplicado. Está pensado como una referencia más que como una revisión exhaustiva.\n","\n","Para mostrar como realizar los cálculos involucrados en Python utilizamos las librerías más habituales como son `numpy` y `Scipy`. Para desarrollos más complejos se aconsjea acudir a las librerías `Pytorch` y `TensorFlow`."],"metadata":{"id":"eFIPVHXZ3Zgb"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"8FeAhsyHMpn1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Escalares, Vectores, Matrices y Tensores</font>"],"metadata":{"id":"EF5y1-3ji__P"}},{"cell_type":"markdown","source":["El estudio del álgebra lineal implica varios tipos de objetos matemáticos:\n","\n","**Escalares**: Un escalar es un número único. Normalmente, los escalares se denominan con minúsculas y, cuando los introducimos, especificamos qué tipo de número son. Podemos decir $a \\in \\mathbb{R}$ para indicar que $a$ es un número real, o $a \\in \\mathbb{N}$ para indicar que $a$ es un número natural."],"metadata":{"id":"PYGlxH_fjzMK"}},{"cell_type":"code","source":["# Definendo un escalar real\n","a = 7.5\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-l0ZVfmmKjz","outputId":"2282d128-1f31-43c5-d688-69535eab4026"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7.5"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["**Vectores**: Un vector es una secuencia ordenada o desordenada de números, de forma que cada uno de ellos se puede identificar según la posición que ocupa en la secuencia. Los vectores se notan mediante una letra minúscula en negrita y cada uno de los elementos se identifica mediante la misma letra y un subíndice en función de la posición que ocupa. De esta forma:\n","\n","$$\\mathbf{x} = [x_1, x_2,...,x_n]$$\n","\n","representa al vector $\\mathbf{x}$  de dimensión $n$ (1 fila y $n$ columnas). En términos de análisis geométrico un vector de dimensión $n$ puede ser visto como las coordenadas de un punto en el espacio $\\mathbb{R}^n$. "],"metadata":{"id":"XDyAfwp2ncad"}},{"cell_type":"code","source":["# Definimos un vector de dimensión 4\n","x = np.array([-1.1,0.0,3.6,-7.2])\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dQp4ROsMivd","outputId":"b52b3932-608a-4998-f4d0-39128d5e96fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1.1,  0. ,  3.6, -7.2])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**Matrices**: Una matriz es una estructura bidimensional de números, donde cada elemento se identifica por dos índices en lugar de uno solo (fila y columna). Solemos dar a las matrices nombres de variables en mayúsculas y en negrita, como $\\mathbf{A}$. Si la matriz tiene $m$ filas y $n$ columnas entonces diremos que $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}$. En la notación habitual tenemos que:\n","\n","$$\\mathbf{A} = \n","\\begin{bmatrix}\n","a_{11} & a_{12} & ... & a_{1n}\\\\\n","a_{21} & a_{22} & ... & a_{2n}\\\\\n","... & ... & ... & ...\\\\\n","a_{m1} & a_{m2} & ... & a_{mn}\n","\\end{bmatrix}\n","$$\n","\n","representa a la matriz $\\mathbf{A}$ de dimensiones $m \\times n$ o de forma simplificada escribimos $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$.\n","\n","En Python podemos definir una matriz mediante la función array concatenando los vectores necesarios para alcanzar el número de filas deseado.\n"],"metadata":{"id":"J1OZ5GDxQaFq"}},{"cell_type":"code","source":["# Definimos una matriz de dimensiones 3X4 (concatenamos tres vectores de dimensión 4)\n","A = np.matrix([[0.0, 1.0, -2.3, 0.1], \n","               [1.3, 4.0, -0.1, 0.0],\n","               [4.1,-1.0, 0.0, 1.7]])\n","A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfaNcvgqS-Ah","outputId":"94152c3b-d1f9-4b9d-9fb8-b4a3b750bccd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["matrix([[ 0. ,  1. , -2.3,  0.1],\n","        [ 1.3,  4. , -0.1,  0. ],\n","        [ 4.1, -1. ,  0. ,  1.7]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["**Tensores**. Los tensores son la generalización de las matrices o arrays a estructuras de datos con más de dos dimensiones. Los tensores se denotan utilizando la misma nomenclatura que para las matrices pero añadiendo las dimensiones que correspondan. Por ejemplo $\\mathbf{A}_{n,m,k}$ representa un array de tres componentes con dimensiones $n$, $m$, y $k$. "],"metadata":{"id":"pSi0Dh9FTwRK"}},{"cell_type":"code","source":["# Definimos un tensor de dimensiones 3X3X3\n","A=np.array([[[1,2,3],[4,5,6],[7,8,9]],\n","            [[10,11,12],[13,14,15],[16,17,18]],\n","            [[19,20,21],[22,23,24],[25,26,27]]])\n","A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uxPPcYrVd50","outputId":"03695d5a-d8e4-4ece-ba7c-3ac2514595bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[ 1,  2,  3],\n","        [ 4,  5,  6],\n","        [ 7,  8,  9]],\n","\n","       [[10, 11, 12],\n","        [13, 14, 15],\n","        [16, 17, 18]],\n","\n","       [[19, 20, 21],\n","        [22, 23, 24],\n","        [25, 26, 27]]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Vectores y matrices especiales</font>"],"metadata":{"id":"VO6Y4Q_3WFQ7"}},{"cell_type":"markdown","source":["Resulta muy habitual utilizar vectores y matrices con estructuras específicas, pero que son de gran utilidad en los cálculos computacionales involucrados en los algoritmos de aprendizaje automático. A continuación se presenta una colección de todos ellos con la función necesaria para su definición en Python."],"metadata":{"id":"orNM4cjkWLQI"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Vectores</font>"],"metadata":{"id":"44LdVbPVXD9g"}},{"cell_type":"markdown","source":["**Vector de ceros**. Es un vector de dimensión $n$ donde todas sus componenetes toman el valor 0 que denotamos como $\\mathbb{0}_n$. "],"metadata":{"id":"TJ--cKdWXPAQ"}},{"cell_type":"code","source":["# Vector de ceros de dimensión 4\n","x = np.zeros(4)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8tKYngTX5v8","outputId":"4e28eba8-8f1d-49ae-d8b4-81cd11b46899"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0.])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["**Vector unitario**. Los vectores unitarios, son vectores compuestos por un solo elemento igual a uno, y el resto a cero. Los vectores unitarios son importantes para entender aplicaciones como las normas. Podemos definir un vector unitario utilizando un vector de ceros. Los vectores unitarios se denotan habitualmente como $\\mathbf{u}_i$, donde el subíndice indica la posición del elemento igual a 1. "],"metadata":{"id":"9rp6rnEZY_p4"}},{"cell_type":"code","source":["# Vector unitario de dimensión 5 con un 1 en la primera posición (u_1)\n","i = 0; n = 5\n","ui = np.zeros(n)\n","ui[i] = 1\n","ui"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"va5hfGQsZUtX","outputId":"652cabd5-2ceb-48d4-cea8-cc40e506122e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 0., 0., 0.])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Vector de unos**. Es un vector donde todas su componentes son igual a 1. Estos vectores se denotan como $\\mathbb{1}_n$"],"metadata":{"id":"gEYZWT29abzu"}},{"cell_type":"code","source":["# Vector de unos de dimensión 6\n","np.ones(6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NFsNa2KamYF","outputId":"d28bff30-8dac-4501-ab32-b9adff129a21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., 1., 1., 1.])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["**Vector aleatorio**. Es un vector donde todas sus componentes son números aleatorios."],"metadata":{"id":"mCa3UEQB3kG_"}},{"cell_type":"code","source":["# Vector aleatorio de dimensión 5\n","np.random.randn(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoifWKN83zrB","outputId":"84c31f2f-141c-45a5-e1c9-f678a0c7b72e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.37030009, -0.79212197, -0.78410983,  2.30812465, -1.74059548])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Matrices</font>"],"metadata":{"id":"cEjoLQKqXLdR"}},{"cell_type":"markdown","source":["**Matriz de ceros**. Es una matriz donde todos los elementos son iguales a cero. En este caso debemos indicar las filas y columnas de la matriz y la denotamos como $\\mathbf{0}_{m,n}$."],"metadata":{"id":"7PMuBmkf5kn0"}},{"cell_type":"code","source":["# matriz de ceros con dos filas y tres columnas\n","np.zeros((2, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdET_Wt65yjq","outputId":"3d533a92-b0cb-47f4-fa5a-8154a0c5e58a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0.],\n","       [0., 0., 0.]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**Matriz de unos**. Es una matriz con todos sus elementos iguales a 1. Lo denotamos como $\\mathbf{1}_{m,n}$."],"metadata":{"id":"dZHhXlP069v8"}},{"cell_type":"code","source":["# matriz de unos con dos filas y tres columnas\n","np.ones((2, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9LzhWCg7TI1","outputId":"eb4684e2-9b08-4b01-eeaf-ff34d308412c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 1., 1.],\n","       [1., 1., 1.]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["**Matriz identidad**. Es una matriz cuadrada (mismas filas y columnas) donde los elementos de la diagonal son iguales a 1 y el resto son cero. La matriz identidad de dimensión $n$ se denota por $\\mathbf{I}_n$."],"metadata":{"id":"pQfBsbQR7r2m"}},{"cell_type":"code","source":["# Matriz identidad de dimensión 3\n","np.identity(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PrV5-JQ77ZV","outputId":"b37e8325-4ed8-48a6-fb55-ce772aaf79a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["**Matriz aleatoria**. Es una matriz donde todos sus elementos son número aleatorios."],"metadata":{"id":"9Y_Y0zHK8p_W"}},{"cell_type":"code","source":["# Matriz aleatoria con dos filas y tres columnas\n","np.random.randn(2, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woNenkPw8eFa","outputId":"821ee1c8-5099-4339-9687-20292bef5ad1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.19084435,  0.63236869, -1.40811851],\n","       [-0.6237726 ,  0.58602612, -0.70088136]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["**Matriz diagonal**. Es una matriz cuadrada donde los elementos de la diagonal se corresponden con un vector de la misma dimensión que el número de filas de la matriz, y donde el resto de elementos son cero."],"metadata":{"id":"bLVm5xiC8_eN"}},{"cell_type":"code","source":["# Matriz diagonal a partir del vector x=[1, 2, 3]\n","np.diag([1,2,3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ER4m6Ig_9QWH","outputId":"907dc017-5418-41aa-b604-34dc992a7e18"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 0],\n","       [0, 2, 0],\n","       [0, 0, 3]])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["**Matriz triangular inferior**. Una matriz cuadrada se dice triangular inferior si todos los elementos por encima de la diagonal son igual a cero. En el caso más sencillo todos los elementos de la diagonal y por debajo de ella son iguales a 1."],"metadata":{"id":"RJE1eMOehLgX"}},{"cell_type":"code","source":["# Matriz tringular inferior de dimensiones 3*3\n","np.tri(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JmC8eHDOhxwq","outputId":"6a75897d-5ea7-4e6e-8b5e-4fe87cdb113c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [1., 1., 0.],\n","       [1., 1., 1.]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["**Matriz traspuesta**. La matriz traspuesta de una matriz $\\mathbf{A}$, que denotamos por $\\mathbf{A}^T$, se obtiene al intercambiar filas y columnas en una matriz."],"metadata":{"id":"9TSDbLXZGj_u"}},{"cell_type":"code","source":["A = np.array([[0, 2, 1],\n","              [1, 4, 2]])\n","A.T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTWRkidKGxay","outputId":"6981425a-9496-4f8c-e45e-7d09d23f0132"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1],\n","       [2, 4],\n","       [1, 2]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**Matriz simétrica**. Las matrices simétricas son la matrices cuadradas tales que $\\mathbf{A} = \\mathbf{A}^T$."],"metadata":{"id":"Go6PKN2lNDpS"}},{"cell_type":"markdown","source":["**Matriz antidiagonal**. Las matrices con todos los elementos iguales a cero salvo los de la antidiagonal se denomina matriz antidiagonal.\n","\n","$$\\mathbf{A} = \n","\\begin{bmatrix}\n","0 & 0 & 2\\\\\n","0 & 1 & 0\\\\\n","-1 & 0 & 0\n","\\end{bmatrix}\n","$$"],"metadata":{"id":"_2HHbb5PN-Wk"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Operaciones con vectores</font>"],"metadata":{"id":"5qsEAcq3iTap"}},{"cell_type":"markdown","source":["Se presentan a continuación las operaciones algebráicas con vectores."],"metadata":{"id":"pRht2T8eigxE"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Operaciones elementales</font>"],"metadata":{"id":"_v5yNNUAZ31_"}},{"cell_type":"markdown","source":["**Suma de vectores**. Dados dos vectores de dimensión $n$, $\\mathbf{x} = [x_1,...,x_n]$ e $\\mathbf{y} = [y_1,...,y_n]$, se define su suma como la suma/diferencia elemento a elemento:\n","\n","$$\\mathbf{x} + \\mathbf{y} = [x_1+y_1,...,x_n+y_n]$$\n","\n","\n","Las propiedades fundamentales que verifican la suma de vectores son conmutatividad y asociatividad. "],"metadata":{"id":"FBBXopQ-jMpF"}},{"cell_type":"code","source":["# Definición de vectores\n","x = np.array([1, 3, 5, 7, 9])\n","y = np.array([0, 2, 4, 6, 8])\n","suma = x + y\n","print('La suma es:',suma)\n","resta = x - y\n","print('La resta es:',resta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFPZPKDrkOSc","outputId":"d94ed675-ccf2-46a7-a2e0-dfbd5af26444"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["La suma es: [ 1  5  9 13 17]\n","La resta es: [1 1 1 1 1]\n"]}]},{"cell_type":"markdown","source":["**Multiplicación por un escalar**. Dado un escalar $a \\in \\mathbb{R}$ y un vector $\\mathbf{x} = [x_1,...,x_n] \\in \\mathbb{R}^n$, se define el producto entre ambos como:\n","\n","$$a\\mathbf{x} = [ax_1,...,ax_n]$$\n","\n","Dados dos escalares $a \\in \\mathbb{R}$ y $b \\in \\mathbb{R}$, y dos vectores $\\mathbf{x} \\in \\mathbb{R}^n$ e $\\mathbf{y} \\in \\mathbb{R}^n$se verifican las propiedades siguientes:\n","\n","* $(ab)\\mathbf{x} = a(b\\mathbf{x})$\n","* $(a + b)\\mathbf{x} = a\\mathbf{x} + b\\mathbf{x}$\n","* $a(\\mathbf{x} + \\mathbf{y}) =a\\mathbf{x} + a\\mathbf{y}$\n"],"metadata":{"id":"15S9yXiYGYpl"}},{"cell_type":"code","source":["x = np.array([1, 3, 5, 7, 9])\n","a = 2\n","print(a*x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ei5Ly6boZUzC","outputId":"9d2fc77a-dc6f-445f-a74c-49ca6969bc11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 2  6 10 14 18]\n"]}]},{"cell_type":"markdown","source":["**Vector traspuesto**. Dado un vector $\\mathbf{x} = [x_1,...,x_n] \\in \\mathbb{R}^n$ se define su trapuesto, denotado por $\\mathbf{x}^{T}$, como el intercambio de filas por columnas, es decir:\n","\n","$$\\mathbf{x}^{T} = \n","\\begin{bmatrix}\n","x_1\\\\\n","x_2\\\\\n","...\\\\\n","x_n\n","\\end{bmatrix}$$"],"metadata":{"id":"adc0ZMaeeJG8"}},{"cell_type":"markdown","source":["**Producto interno o producto escalar**. Dados dos  vectores $\\mathbf{x} \\in \\mathbb{R}^n$ e $\\mathbf{y} \\in \\mathbb{R}^n$, se define el producto interno o producto escalar como:\n","\n","$$<\\mathbf{x},\\mathbf{y}> = \\mathbf{x}\\mathbf{y} = \\sum_{i=1}^n x_iy_i.$$"],"metadata":{"id":"waOLt-xrjBhr"}},{"cell_type":"code","source":["# Definición de vectores\n","x = np.array([1, 3, 5, 7, 9])\n","y = np.array([0, 2, 4, 6, 8])\n","# Producto escalar\n","np.inner(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-ygErEgkCHy","outputId":"0372ff78-d4a3-4b0a-83cb-969339ae95c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["140"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Norma de un vector</font>"],"metadata":{"id":"Za43--VLlWLK"}},{"cell_type":"markdown","source":["La medición de vectores es otra operación importante en las aplicaciones de aprendizaje automático. Intuitivamente, podemos pensar en la norma o la longitud de un vector como la distancia entre su \"origen\" y su \"final\". Las normas mapean vectores a valores no negativos. En este sentido son funciones que asignan la longitud a un vector. A continuación, mostramos las propiedades que debe verificar una norma para ser considerada como tal y presentamos los tipos más utilizados. En todos los casos consderamos un vector $\\mathbf{x} \\in \\mathbb{R}^n$.\n"],"metadata":{"id":"Cjha02y6lkxK"}},{"cell_type":"markdown","source":["Dado un escalar $a$ y dos vectores $\\mathbf{x}$ e $\\mathbf{y}$, las propiedades que debe cumplir una función para considerarse una norma son:\n","\n","1. Homogeneidad absoluta\n","\n","$$\\|a\\mathbf{x}\\| = |a|\\|\\mathbf{x}\\|$$\n","\n","2. Desigualdad triangular\n","\n","$$\\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|$$\n","\n","3. Definida positiva\n","\n","$$\\|\\mathbf{x}\\| \\geq 0$$\n","$$\\|\\mathbf{x}\\| =0 \\Leftrightarrow \\mathbf{x} = \\mathbf{0}$$\n","\n","\n"],"metadata":{"id":"3jyK8k7y_ncc"}},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Norma euclídea</font>"],"metadata":{"id":"1VuQkS3_mJxx"}},{"cell_type":"markdown","source":["La norma euclidiana o norma $L_2$ es una de las normas más populares en el aprendizaje automático. Su uso está tan extendido que a veces se denomina simplemente \"la norma\" de un vector. Se define como:\n","\n","$$\\|\\mathbf{x}\\|_2 = \\sqrt{ \\sum_{i=1}^n x^2_i } = \\sqrt{<x,x>}$$"],"metadata":{"id":"fDkdNphomlyR"}},{"cell_type":"code","source":["# Definición de vector\n","x = np.array([1, 3, 5, 7, 9])\n","# norma euclídea\n","np.linalg.norm(x, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbKN2vcSq3dw","outputId":"a6973797-9bb5-4ed3-f4ed-31c74362fe78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.84523257866513"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["A partir de ahora identificaremos la norma $L_2$ como $\\|\\mathbf{x}\\|_2 = \\|\\mathbf{x}\\|$"],"metadata":{"id":"-m2J5rVCwzQE"}},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Norma Manhattan</font>"],"metadata":{"id":"keAK9tQrsVLd"}},{"cell_type":"markdown","source":["La norma de Manhattan o $L_1$ recibe su nombre por analogía con la medición de distancias al moverse en Manhattan, Nueva York. Como Manhattan tiene forma de cuadrícula, la distancia entre dos puntos cualesquiera se mide moviéndose en líneas verticales y horizontales (en lugar de diagonales como en la norma euclidiana). Se define como:\n","\n","$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n |x_i|,$$\n","\n","donde $|x_i|$ es el valor absoluto de la componente $i$. Se prefiere la norma $L_1$ cuando se discrimina entre elementos que son exactamente cero y elementos que son pequeños pero no cero."],"metadata":{"id":"u6UFdNp8sdgB"}},{"cell_type":"code","source":["# Definición de vector\n","x = np.array([1, 3, 5, 7, 9])\n","# norma manhattan\n","np.linalg.norm(x, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"me0pvak2tcwF","outputId":"e7551b65-ace5-4f3e-dfdb-d38303f4a891"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["25.0"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Norma máxima</font>"],"metadata":{"id":"ijx6IXlvuRSW"}},{"cell_type":"markdown","source":["La norma máxima o norma del infinito es simplemente el valor absoluto del mayor elemento del vector. Se define como:\n","\n","$$\\|\\mathbf{x}\\|_{\\infty} = \\underset{i}{max}  |x_i|,$$"],"metadata":{"id":"F2rEM8cwutNI"}},{"cell_type":"code","source":["# Definición de vector\n","x = np.array([1, 3, 5, 7, 9])\n","# norma manhattan\n","np.linalg.norm(x, np.inf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_bPSDc1vBJQ","outputId":"8dd82ff5-cfbd-412e-8dba-a9e222304e4c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.0"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Distancia, ángulos y ortogonalidad</font>"],"metadata":{"id":"-kGySZAdwAvJ"}},{"cell_type":"markdown","source":["La distancia es un concepto relacional. Se refiere a la longitud (o norma) de la diferencia entre dos vectores. Por lo tanto, utilizamos normas y longitudes para medir la distancia entre vectores. Los conceptos de ángulo y ortogonalidad también están relacionados con la interpretación geométrica de los vectores. En el aprendizaje automático, el ángulo entre un par de vectores se utiliza como medida de similitud de vectores."],"metadata":{"id":"StElnkw3wJUJ"}},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Distancia</font>\n","\n"],"metadata":{"id":"c2e27mdmxS4w"}},{"cell_type":"markdown","source":["Dados dos puntos $\\mathbf{x} \\in \\mathbb{R}^n$ e $\\mathbf{y} \\in \\mathbb{R}^n$ se define la distancia ($d$) entre ellos como el producto escalar del vector diferencia o la norma euclídea de la diferencia:\n","\n","$$d(\\mathbf{x}, \\mathbf{y}) = \\|x-y\\| = <x-y, x-y>$$"],"metadata":{"id":"Y8TnOFvZxcUJ"}},{"cell_type":"code","source":["# Definición de vectores\n","x = np.array([1, 3, 5, 7, 9])\n","y = np.array([0, 2, 4, 6, 8])\n","# Distancia\n","np.linalg.norm(x-y, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Risg-zD8yLqZ","outputId":"b1998e90-19df-42c8-fdb5-b1d2503eb297"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.23606797749979"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Ángulo entre dos vectores</font>\n"],"metadata":{"id":"GFiChvkXyqv3"}},{"cell_type":"markdown","source":["Dados dos vectores $\\mathbf{x} \\in \\mathbb{R}^n$ e $\\mathbf{y} \\in \\mathbb{R}^n$ se define el coseno del angulo ($\\theta$) entre ellos como:\n","\n","$$cos \\theta = \\frac{<x,y>}{\\|x\\|\\|y\\|}$$"],"metadata":{"id":"XqNaYUBqyzam"}},{"cell_type":"code","source":["# Vectores\n","x = np.array([1, 3])\n","y = np.array([5, 7])\n","# Coseno del ángulo que forman\n","cos_theta = (np.inner(x, y)) / (np.linalg.norm(x,2) * np.linalg.norm(y,2))\n","# Ángulo en radianes\n","cos_inverse = np.arccos(cos_theta)\n","# Ángulo en grados\n","cos_inverse * ((180)/np.pi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RD4qjTH0gOf","outputId":"19a38da9-0e88-4078-971f-36d2f2933f56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17.10272896905239"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Ortogonalidad entre dos vectores</font>\n"],"metadata":{"id":"0Hd1ecrF1iHK"}},{"cell_type":"markdown","source":["La ortogonalidad suele utilizarse indistintamente con la \"independencia\", aunque son conceptos matemáticamente diferentes. La ortogonalidad puede verse como una generalización de la perpendicularidad a los vectores en cualquier número de dimensiones.\n","\n","Decimos que un par de vectores $\\mathbf{x} \\in \\mathbb{R}^n$ e $\\mathbf{y} \\in \\mathbb{R}^n$ son ortogonales si su producto escalar es cero:\n","\n","$$<x, y>=0.$$\n","\n","Utilizando la definición de ángulo, si el producto escalar entre los dos vectores es igual a cero implica que el ángulo que se forma entre ambos es de 90 grados."],"metadata":{"id":"EPpGjgD61neW"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Dependencia e independencia lineal de vectores</font>"],"metadata":{"id":"nTPJYCr83o4c"}},{"cell_type":"markdown","source":["Un conjunto de vectores es linealmente dependiente si al menos un vector puede obtenerse como combinación lineal de otros vectores del conjunto. \n","\n","Hay una definición más rigurosa (pero algo más difícil de entender) de la dependencia lineal. Consideremos un conjunto de vectores $\\mathbf{x}_1,...,\\mathbf{x}_k$  y escalares $\\beta_1,...,\\beta_k$. Si hay una forma de obtener la combinación\n","\n","$$0 = \\sum_{i=1}^k \\beta_i\\mathbf{x}_i$$\n","\n","con al menos un $\\beta \\neq 0$, tenemos vectores linealmente dependientes. En otras palabras, si podemos obtener el vector cero como una combinación lineal de los vectores del conjunto, con pesos que no son todos cero, tenemos un conjunto linealmente dependiente.\n","\n","Un conjunto de vectores es linealmente independiente si ningún vector puede obtenerse como combinación lineal de otros vectores del conjunto. \n","\n","La importancia de los conceptos de dependencia e independencia lineal se aclarará en temas más avanzados. Por ahora, los puntos importantes a recordar son: los vectores linealmente dependientes contienen información redundante, mientras que los vectores linealmente independientes no."],"metadata":{"id":"ACnGd-3w3uhH"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Operaciones con matrices</font>"],"metadata":{"id":"3VoDJlK6Atao"}},{"cell_type":"markdown","source":["Se presentan a continuación las principales operaciones que se pueden realizar con matrices."],"metadata":{"id":"JobwdkuWBkcP"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Operaciones elementales</font>"],"metadata":{"id":"Yj78KrjjGpxq"}},{"cell_type":"markdown","source":["**Suma**. Dadas dos matrices $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ y $\\mathbf{B} = \\{b_{ij}\\}_{m,n}$ se define la suma de ambas como:\n","\n","$$\\mathbf{A} + \\mathbf{B} = \n","\\begin{bmatrix}\n","a_{11} + b_{11} & ... & a_{1n}+b_{1n}\\\\\n","...&...&...\\\\\n","a_{m1}+b_{m1} & ... & a_{mn}+b_{mn}\n","\\end{bmatrix}\n","$$"],"metadata":{"id":"3u_qiZTqEaAH"}},{"cell_type":"code","source":["# Definimos matrices\n","A = np.array([[0,2],\n","              [1,4]])\n","B = np.array([[3,1],\n","              [-3,2]])\n","# Suma\n","np.add(A,B)\n","# Se puede hacer directamente como A+B"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tg2LlzfvGsDx","outputId":"35352507-737d-4161-d0b8-fd542e1ba08f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 3,  3],\n","       [-2,  6]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["**Producto por un escalar**. Sea un escalar $k$ y una matriz $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$. Se define el producto de la matriz por un escalar como el producto de cada uno de los elementos de la matriz por el escalar:\n","\n","$$k\\mathbf{A} = \n","\\begin{bmatrix}\n","ka_{11}& ... & ka_{1n}\\\\\n","...&...&...\\\\\n","ka_{m1} & ... & ka_{mn}\n","\\end{bmatrix}\n","$$\n","\n","o de forma abreviada como $k\\mathbf{A} = \\{ka_{ij}\\}_{m,n}$."],"metadata":{"id":"DgVEh0ViHuRp"}},{"cell_type":"code","source":["# Escalar y matriz\n","k = 2\n","A = np.array([[1,2],\n","              [3,4]])\n","# Producto\n","np.multiply(k, A)\n","# también se puede hacer como k*A"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dpCVmGAIjta","outputId":"63db6c5b-41dd-427e-baad-c879d4c0c759"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2, 4],\n","       [6, 8]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["**Producto matricial**. La multiplicación de matrices tiene ciertas características especiales. Para poder realizar el cálculo el número de columnas de la primera matriz tiene que ser igual al número de filas de la segunda matriz. Dadas dos matrices $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ y $\\mathbf{B} = \\{b_{ij}\\}_{n,p}$ una forma de ver la multiplicación matricial es tomando una serie de productos donde multiplicamos: la 1ª columna de A por la 1ª fila de B, la 2ª columna de A por la 2ª fila de B, hasta la enésima columna de A por la enésima fila de B. De esta forma:\n","\n","$$AB = \n","\\begin{bmatrix}\n","\\sum_{l=1}^n a_{1l}b_{l1} & ... & \\sum_{l=1}^n a_{1l}b_{lp}\\\\\n","...&...&...\\\\\n","\\sum_{l=1}^n a_{ml}b_{l1} & ... & \\sum_{l=1}^n a_{ml}b_{lp}\n","\\end{bmatrix}\n","$$\n","\n","La propiedades del producto matricial son:\n","\n","1. Asociatividad: $(\\mathbf{A}\\mathbf{B})\\mathbf{C} = \\mathbf{A}(\\mathbf{B}\\mathbf{C})$\n","2. Asociatividad con multiplicación escalar: $k(\\mathbf{A}\\mathbf{B})=(k\\mathbf{A})\\mathbf{B}$ \n","3. Distributiva con la suma: $\\mathbf{A}(\\mathbf{B}+\\mathbf{C})=\\mathbf{A}\\mathbf{B}+\\mathbf{A}\\mathbf{C}$\n","4. Traspuesta del producto: $(\\mathbf{A}\\mathbf{B})^{T} = \\mathbf{B}^{T}\\mathbf{A}^{T}$"],"metadata":{"id":"b9lyyjaqI-Xr"}},{"cell_type":"code","source":["# Definimos matrices\n","A = np.array([[0,2],\n","              [1,4]])\n","B = np.array([[3,1],\n","              [-3,2]])\n","# Producto\n","np.dot(A,B)\n","# Se puede hacer directamente como A@B"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xApnWWODH2OF","outputId":"bd2f05f4-ebc7-493c-f5c1-b3dd5fb2fbc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-6,  4],\n","       [-9,  9]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["**Matriz inversa**. Dada una matriz cuadrada $\\mathbf{A} = \\{a_{ij}\\}_{n,n}$, se define la inversa de dicha matriz, y se denota por $\\mathbf{A}^{-1}$, a la matriz que al multiplicar por $\\mathbf{A}$ nos da la matriz identidad, es decir:\n","\n","$$\\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}_n$$"],"metadata":{"id":"cjrNnssLIMqq"}},{"cell_type":"markdown","source":["La matriz inversa nos permite resolver los sistemas de ecuaciones lineales de la forma:\n","\n","$$\\mathbf{A}\\mathbf{x} = \\mathbf{y}$$\n","\n","ya que\n","\n","$$\\mathbf{x} = \\mathbf{A}^{-1}\\mathbf{y}$$"],"metadata":{"id":"l-1oyuCYJE8o"}},{"cell_type":"code","source":["# Definimos matriz\n","A = np.array([[1, 2, 1],\n","              [4, 4, 5],\n","              [6, 7, 7]])\n","# Obtenemos inversa\n","Ainv = np.linalg.inv(A)\n","Ainv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COPYV_FiKnpf","outputId":"9dcddbcd-c34e-498f-d95c-4b879fc37524"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-7., -7.,  6.],\n","       [ 2.,  1., -1.],\n","       [ 4.,  5., -4.]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Verificamos la propiedad"],"metadata":{"id":"VxZSLr8UK6qH"}},{"cell_type":"code","source":["# Ajustamos decimales por los ajustes numéricos\n","np.round(np.dot(Ainv,A))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itsBgwSuK9yn","outputId":"b07a5ba9-1741-4f00-f86e-3e0f335878fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.,  0.,  0.],\n","       [ 0.,  1., -0.],\n","       [ 0., -0.,  1.]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["**Producto Hadamard o elemento a elemento**. Dadas dos matrices $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ y $\\mathbf{B} = \\{b_{ij}\\}_{n,p}$ el producto elemento a elemento o producto de Hadamard es la multiplicación de cada elemento de la matriz $\\mathbf{A}$ por su correspondiente elemento de la matriz $\\mathbf{B}$:\n","\n","$$\\mathbf{A} \\odot \\mathbf{B} = \n","\\begin{bmatrix}\n","a_{11}b_{11} & ... & a_{1n}b_{1n}\\\\\n","...&...&...\\\\\n","a_{m1}b_{m1} & ... & a_{mn}b_{mn}\n","\\end{bmatrix}\n","$$"],"metadata":{"id":"JIMNIsBfLv-B"}},{"cell_type":"code","source":["# Definimos matrices\n","A = np.array([[0,2],\n","              [1,4]])\n","B = np.array([[3,1],\n","              [-3,2]])\n","# Producto hadamard\n","np.multiply(A,B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnlIuAbGMtkN","outputId":"7be7c8a8-4921-4c1f-e363-7e932c58bf6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  2],\n","       [-3,  8]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Norma de una matriz</font>"],"metadata":{"id":"tD4jd4xLGzXE"}},{"cell_type":"markdown","source":["Al igual que con los vectores, podemos medir el tamaño de una matriz calculando su norma. Hay múltiples formas de definir la norma de una matriz, siempre que satisfaga las mismas propiedades definidas para las normas de los vectores: (1) absolutamente homogénea, (2) desigualdad triangular, (3) definida positiva. En nuestro caso mostramos las más utilizadas."],"metadata":{"id":"mEDROvQpIXYR"}},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Norma de Frobenius</font>"],"metadata":{"id":"dUgYWo07IxGq"}},{"cell_type":"markdown","source":["La norma de Frobenius es una norma obtenida elemento a elemento que lleva el nombre del matemático alemán Ferdinand Georg Frobenius. Denotamos esta norma como $\\|\\mathbf{A}\\|_F$. Se puede considerar esta norma como la conversión de la matriz en un vector. Por ejemplo, una matriz de 3×3 se convertiría en un vector con $n=9$ entradas, del cual obtenemos a norma. Dada una matriz $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ definimos la norma de Frobenius como:\n","\n","$$\\|\\mathbf{A}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n a_{ij}^2}$$"],"metadata":{"id":"KL2ItBeqI4s7"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [4, 5, 6], \n","              [7, 8, 9]])\n","# Norma Frobenius\n","np.linalg.norm(A, 'fro')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Epn2gxGVK-aG","outputId":"11299ac8-e322-4dbf-b4c8-6d76ee95f716"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16.881943016134134"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### <font color=\"steelblue\">Norma máxima</font>"],"metadata":{"id":"kAjgREJZLmI4"}},{"cell_type":"markdown","source":["La norma máxima o norma infinita de una matriz es igual a la mayor suma del valor absoluto de los vectores de las filas. Dada una matriz $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ definimos la norma máxima, que denotamos por $\\|\\mathbf{A}\\|_{max}$, como:\n","\n","$$\\|\\mathbf{A}\\|_{max} = \\underset{i}{max} \\sum_{j=1}^n |a_{ij}|$$\n"],"metadata":{"id":"R-eoOMNWLpvn"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [4, 5, 6], \n","              [7, 8, 9]])\n","# Calculamos la norma\n","np.linalg.norm(A, np.inf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZkcUi0oQWTE","outputId":"f337f541-8551-4b5e-a584-b9b79bbc166f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24.0"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Características de una matriz</font>"],"metadata":{"id":"rVjwCWT6F-lN"}},{"cell_type":"markdown","source":["Existen diferentes cálculos numéricos a partir de una matriz que nos permiten caracterizarla. "],"metadata":{"id":"Zst2vAHDGJKg"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Rango, traza, y determinante</font>"],"metadata":{"id":"j1R3c5KbStcO"}},{"cell_type":"markdown","source":["**Rango**. Dada una matriz $\\mathbf{A} = \\{a_{ij}\\}_{m,n}$ se define el rango de $\\mathbf{A}$, que denotamos por $rank(\\mathbf{A})$, como el número máximo de filas o columnas linealmente independientes. "],"metadata":{"id":"fgqeks_qUaJB"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [4, 5, 6], \n","              [7, 8, 9]])\n","# Calculamos rango\n","np.linalg.matrix_rank(A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbRRozLlWZ8j","outputId":"687abac7-1cf7-49eb-9a4d-b9eebba49cde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["**Rango**. Dada una matriz cuadrada $\\mathbf{A} = \\{a_{ij}\\}_{m,m}$ se define la traza de $\\mathbf{A}$, que denotamos por $tr(\\mathbf{A})$, como la suma de los elementos de la diagonal:\n","\n","$$tr(\\mathbf{A}) = \\sum_{i=1}^m a_{ii}$$"],"metadata":{"id":"G6z8sD1nXACz"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [4, 5, 6], \n","              [7, 8, 9]])\n","# Calculamos la traza\n","np.trace(A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QybX6rxRYDPN","outputId":"d8dc21bd-0f96-43aa-9e53-7d5501a3dfe3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**Determinante**. Dada una matriz cuadrada $\\mathbf{A} = \\{a_{ij}\\}_{m,m}$ el determinante de $\\mathbf{A}$, que denotamos por $det(\\mathbf{A})$ o $|\\mathbf{A}|$, es un importante concepto del algebra matricial. Es un indicativo muy rápido para identificar si el conjunto de vectores (por filas o columnas) que forman la matriz son linealmente independientes. Si el determinate es 0 hay filas o columnas linealmente dependientes, mientras que si es distinto de cero todas las filas o columnas son linealmente independentes. "],"metadata":{"id":"G5sBASp9d5PQ"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [4, 5, 6], \n","              [7, 8, 9]])\n","# Calculamos el determinante\n","np.linalg.det(A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLrxInCWece8","outputId":"6e0bbe97-8743-4121-950c-2cc596b2d52d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Propiedades rango, traza, y determinante</font>"],"metadata":{"id":"Orme7Tzkj2ud"}},{"cell_type":"markdown","source":["* Dadas las matrices $\\mathbf{A} = \\{a_{ij}\\}_{m,m}$, $\\mathbf{B} = \\{b_{ij}\\}_{m,m}$, y $k \\in \\mathbb{R}$ se verifica que:\n","\n","$$tr(\\mathbf{A} + \\mathbf{B}) = tr(\\mathbf{A}) + tr(\\mathbf{B})$$\n","\n","$$tr(k\\mathbf{A})= ktr(\\mathbf{A})$$\n","\n","$$|k\\mathbf{A}| = k^m|\\mathbf{A}|$$\n","\n","$$|\\mathbf{A}\\mathbf{B}|= |\\mathbf{B}\\mathbf{A}|=|\\mathbf{A}||\\mathbf{B}|$$\n","\n","$$|\\mathbf{A}^{-1}| = |\\mathbf{A}|^{-1}$$\n","\n","$$rank(\\mathbf{A})=m \\Leftrightarrow \\mathbf{A} \\text{ es no singular}$$\n","\n","* Dadas las matrices $\\mathbf{A} = \\{a_{ij}\\}_{n,m}$ y $\\mathbf{B} = \\{b_{ij}\\}_{m,p}$, se verifica que:\n","\n","$$tr(\\mathbf{A}\\mathbf{B})=tr(\\mathbf{B}\\mathbf{A})$$\n","\n","$$rank(\\mathbf{A})=min(n,m)$$\n","\n","$$rank(\\mathbf{A})\\geq 0$$\n","\n","$$rank(\\mathbf{A})=rank(\\mathbf{A}^{T})$$\n","\n","$$rank(\\mathbf{A}^{T}\\mathbf{A})=rank(\\mathbf{A})$$\n","\n","$$rank(\\mathbf{A}+\\mathbf{B}) \\leq rank(\\mathbf{A})+rank(\\mathbf{B})$$\n","\n","$$rank(\\mathbf{A}\\mathbf{B}) \\leq min(rank(\\mathbf{A}),rank(\\mathbf{B}))$$\n","\n","* Dadas las matrices $\\mathbf{A} = \\{a_{ij}\\}_{n,m}$, $\\mathbf{B} = \\{b_{ij}\\}_{m,p}$ y $\\mathbf{C} = \\{c_{ij}\\}_{p,n}$, se verifica que:\n","\n","$$tr(\\mathbf{A}\\mathbf{B}\\mathbf{C})=tr(\\mathbf{B}\\mathbf{C}\\mathbf{A}) = tr(\\mathbf{C}\\mathbf{A}\\mathbf{B})$$"],"metadata":{"id":"xP4PKvhaj68I"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Valores y vectores propios</font>"],"metadata":{"id":"TniUnTOTvfJx"}},{"cell_type":"markdown","source":["Dada una matriz $\\mathbf{A} = \\{a_{ij}\\}_{n,n}$ se definen los valores propios de de dicha matriz como las p-raíces, $k_1,...,k_n$, de la ecuación característica:\n","\n","$$|\\mathbf{A}-\\mathbf{k} \\mathbf{I}_n| = 0,$$\n","\n","donde $\\mathbf{k}=(k_1,...,k_n)$. \n","\n","Los $n$ vectores propios de la matriz $\\mathbf{A}$, $\\mathbf{v}_1,...,\\mathbf{v}_n$, se obtienen a partir de los $n$ valores propios al resolver el sistema:\n","\n","$$\\mathbf{A}\\mathbf{v} = \\mathbf{k} \\mathbf{v}$$\n","\n","donde $\\mathbf{v}$ es una matriz donde las columnas corresponde a cada uno de los $n$ vectores propios de $\\mathbf{A}$."],"metadata":{"id":"ua3YgxnLv0O5"}},{"cell_type":"code","source":["# Definimos la matriz\n","A = np.array([[1, 2, 3],\n","              [5, 4, 6], \n","              [7, 9, 7]])\n","# Obtenemos valores y vectore propios\n","val, vec = np.linalg.eig(A)\n","# En formato complejo\n","print(val)\n","print(vec)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PVjTqIx15Fn","outputId":"e1ae71b2-253c-44b2-9f6e-246c266b3659"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[15.19600263+0.j         -1.59800132+0.11338522j -1.59800132-0.11338522j]\n","[[-0.24616584+0.j         -0.71408301+0.j         -0.71408301-0.j        ]\n"," [-0.54092983+0.j         -0.09430113+0.09464358j -0.09430113-0.09464358j]\n"," [-0.80423709+0.j          0.68126362-0.09008454j  0.68126362+0.09008454j]]\n"]}]},{"cell_type":"markdown","source":["Los valores propios de una matriz son una herramienta muy importante ya que nos permiten relacionar la traza y el determinante de una matriz con dichos valores. De hecho, dada una matriz $\\mathbf{A} = \\{a_{ij}\\}_{n,n}$ si consideramos el vector formado por los valores propios $\\mathbf{k}= [k_1,...,k_n]$ de forma que construímos una matriz diagonal \n","\n","$$\\mathbf{\\Lambda} = \\mathbf{I}_n \\mathbf{k}^T$$\n","\n","podemos ver que:\n","\n","$$|\\mathbf{A}|=|\\mathbf{\\Lambda}|=\\prod_{i=1}^n k_i$$\n","\n","$$tr(\\mathbf{A})=tr(\\mathbf{\\Lambda})=\\sum_{i=1}^n k_i$$"],"metadata":{"id":"-QxsLeO17bvM"}},{"cell_type":"markdown","source":["## <font color=\"steelblue\">Descomposición en valores y vectores propios</font>"],"metadata":{"id":"5n7-pUR1C8pd"}},{"cell_type":"markdown","source":["Las descomposiciones en valores y vectores propios nos permiten escribir las matrices cuadradas en un formato que resulta más cómodo desde le punto de vista computacional cuando estamos trabajando con matrices de grandes dimensiones. Se pueden revisar las referencias presentadas para ver los diferentes tipos con los que nos podemos encontrar. Únicamente recordamos que dichas descomposiciones nos sirven para representar geométricamente vectores de n dimensiones en espacios bidimensionales o tridimensionales."],"metadata":{"id":"sWU7PHrjDQFt"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Referencias y enlaces de interés</font>"],"metadata":{"id":"u6SCdV2q9zaE"}},{"cell_type":"markdown","source":["1. Manual online de Numpy: https://numpy.org/\n","\n","2. Manual online de Scipy: https://scipy.org/\n","\n","3. Mathematics for Machine Learning by Deisenroth, Faisal, and Ong. 1st Ed. [Book link](https://mml-book.github.io/).\n","\n","4. Introduction to Applied Linear Algebra by Boyd and Vandenberghe. 1sr Ed. [Book link](https://web.stanford.edu/~boyd/vmls/).\n","\n","5. Linear Algebra Ch. in Deep Learning by Goodfellow, Bengio, and Courville. 1st Ed. [Chapter link](https://www.deeplearningbook.org/contents/linear_algebra.html).\n","\n","6. Linear Algebra Ch. in Dive into Deep Learning by Zhang, Lipton, Li, And Smola. [Chapter link](https://d2l.ai/chapter_preliminaries/linear-algebra.html).\n","\n","7. Manual online de Pytorch: https://pytorch.org/\n","\n","8. Manual online de TensorFlow: https://www.tensorflow.org/\n","\n"],"metadata":{"id":"YjaXLYPjoriz"}},{"cell_type":"markdown","source":["# <font color=\"steelblue\">Para ampliar contenidos</font>\n"],"metadata":{"id":"oTIajVZ296CM"}},{"cell_type":"markdown","source":["1. Harris, C.R., Millman, K.J., van der Walt, S.J. et al. [Array programming with NumPy](https://www.nature.com/articles/s41586-020-2649-2). Nature 585, 357–362 (2020).\n","\n","2. Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, İlhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E.A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. (2020) [SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python](https://www.nature.com/articles/s41592-019-0686-2?report=reader). Nature Methods, 17(3), 261-272.\n","\n"],"metadata":{"id":"2aF09NtZW4X3"}}]}